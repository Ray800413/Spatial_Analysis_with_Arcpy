{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Spatial Analysis with Arcpy\n",
    "<img src=\"arcpy.png\" style=\"width=300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this exercise is to create utilitarian Python script for use with ArcGIS. The purpose is to walk through traditional spatial analysis workflow using programming language in stead of using ArcGIS software. The Python script will allow you to perform data management, geoprocessing, and visualization in ArcGIS. This Jupter notebook was created outside of ArcGIS to run the standalone Python script. The major tasks involved to complete this exercise include data cleanup with `pandas`, data analysis with `Arcpy`, and result visualization with `ArcGIS API for Python`.\n",
    "\n",
    "Data science and the data scientis is all the rage these days. The major taks of a data scientist involves data cleanup, data analysis, modeling/statistics, engineering and prototyping. Just as data science workflow, a spatial analysis workflow involves multiple steps to get to the final results. Besides, with the massive explosion in both the data generated and retained by companies, it is essential for GIS analysts to equip skills for handling high volumne of data. Python, R, and SQL are very popular amongst the data science community. Hence, it is important for us, GISers, to become familiar with the languages to enable us to work more effeciently and elegantly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used for this exercise includes \n",
    "- (1) A csv file of 911 calls in Baltimore from 2015-2018\n",
    "- (2) Baltimore district shapefile\n",
    "- (3) TIGER/Line shapefile of Maryland census tract "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Workflow\n",
    "### 2.1 Data Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, try to open **\"911_Police_calls_for_Service.csv\"** in Excel and see what happens? Yes, you saw an error message prompted out and told you Excel was overloaded. Why? Because Excel is only able to handle one million of rows at a time. \n",
    "\n",
    "Now, could you come up with any solution to check and clean up this data instead of using Excel? You may have guessed that it can be opened and read using programming language and you are correct. To handle this cumbersome file, we will use the python library - `pandas`. \n",
    "\n",
    "Now, Let's look how `pandas` can help us carry out data munging. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Read the File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import `pandas` and read the file into dataframe.\n",
    "> `pandas` dataframe is two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns). It consists of three principal components, the *data*, *rows*, and *columns*. It enables us to view, manage, and modify the data much easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordId</th>\n",
       "      <th>callDateTime</th>\n",
       "      <th>priority</th>\n",
       "      <th>district</th>\n",
       "      <th>description</th>\n",
       "      <th>callNumber</th>\n",
       "      <th>incidentLocation</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1423624</td>\n",
       "      <td>05/04/2016 09:58:00 PM</td>\n",
       "      <td>High</td>\n",
       "      <td>ND</td>\n",
       "      <td>SILENT ALARM</td>\n",
       "      <td>P161253035</td>\n",
       "      <td>400 WINSTON AV</td>\n",
       "      <td>400 WINSTON AV\\nBALTIMORE, MD\\n(39.349792, -76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1402097</td>\n",
       "      <td>04/27/2016 03:57:00 PM</td>\n",
       "      <td>Medium</td>\n",
       "      <td>SW</td>\n",
       "      <td>911/HANGUP</td>\n",
       "      <td>P161182081</td>\n",
       "      <td>1400 BRADDISH AV</td>\n",
       "      <td>1400 BRADDISH AV\\nBALTIMORE, MD\\n(39.303941, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1420176</td>\n",
       "      <td>05/03/2016 06:40:00 PM</td>\n",
       "      <td>Medium</td>\n",
       "      <td>ED</td>\n",
       "      <td>DISORDERLY</td>\n",
       "      <td>P161242705</td>\n",
       "      <td>200 E NORTH AV</td>\n",
       "      <td>200 E NORTH AV\\nBALTIMORE, MD\\n(39.311294, -76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1423653</td>\n",
       "      <td>05/04/2016 10:10:00 PM</td>\n",
       "      <td>Medium</td>\n",
       "      <td>NE</td>\n",
       "      <td>911/NO  VOICE</td>\n",
       "      <td>P161253068</td>\n",
       "      <td>2500-1 HARFORD RD</td>\n",
       "      <td>2500 1 HARFORD RD\\nBALTIMORE, MD\\n(39.316763, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1417949</td>\n",
       "      <td>05/03/2016 12:29:00 AM</td>\n",
       "      <td>Non-Emergency</td>\n",
       "      <td>SD</td>\n",
       "      <td>Private Tow</td>\n",
       "      <td>P161240063</td>\n",
       "      <td>100 W PATAPSCO AV</td>\n",
       "      <td>100 W PATAPSCO AV\\nBALTIMORE, MD\\n(39.239215, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recordId            callDateTime       priority district    description  \\\n",
       "0   1423624  05/04/2016 09:58:00 PM           High       ND   SILENT ALARM   \n",
       "1   1402097  04/27/2016 03:57:00 PM         Medium       SW     911/HANGUP   \n",
       "2   1420176  05/03/2016 06:40:00 PM         Medium       ED     DISORDERLY   \n",
       "3   1423653  05/04/2016 10:10:00 PM         Medium       NE  911/NO  VOICE   \n",
       "4   1417949  05/03/2016 12:29:00 AM  Non-Emergency       SD    Private Tow   \n",
       "\n",
       "   callNumber   incidentLocation  \\\n",
       "0  P161253035     400 WINSTON AV   \n",
       "1  P161182081   1400 BRADDISH AV   \n",
       "2  P161242705     200 E NORTH AV   \n",
       "3  P161253068  2500-1 HARFORD RD   \n",
       "4  P161240063  100 W PATAPSCO AV   \n",
       "\n",
       "                                            location  \n",
       "0  400 WINSTON AV\\nBALTIMORE, MD\\n(39.349792, -76...  \n",
       "1  1400 BRADDISH AV\\nBALTIMORE, MD\\n(39.303941, -...  \n",
       "2  200 E NORTH AV\\nBALTIMORE, MD\\n(39.311294, -76...  \n",
       "3  2500 1 HARFORD RD\\nBALTIMORE, MD\\n(39.316763, ...  \n",
       "4  100 W PATAPSCO AV\\nBALTIMORE, MD\\n(39.239215, ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the csv file into dataframe\n",
    "df = pd.read_csv(\"911_Police_Calls_for_Service.csv\")\n",
    "# Display the first five rows in the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many rows and columns are there in the dataset and display columns' names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 4078343 \n",
      "Total columns: 8\n",
      "Columns: Index(['recordId', 'callDateTime', 'priority', 'district', 'description',\n",
      "       'callNumber', 'incidentLocation', 'location'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display the number of columns and rows inside the dataframe\n",
    "print(\"Total rows: {0} \\nTotal columns: {1}\".format(df.shape[0], df.shape[1]))\n",
    "print(\"Columns: {}\".format(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see that. Ther are over four millions rows!! No wonder Excel crashed. In fact, you will only ongoingly face this such large file in this big data era. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here let's consider what kinds of cleanup are required for our later analysis. \n",
    "- *Remove unnecessary columns containing inapplicable information*: Not all the columns contain information we need for analysis. \n",
    "- *Remove records(rows) containing empty values*: The file might have blank cells, and this will be deonted by *\"NaN\"* in `pandas`. \n",
    "- *Derive year, month, and weekday from the \"callDateTime\" field*: In this exercise, we are interested in which month and weekday has the highest number of  emergency 911 calls. Since all this information are combined together, we need to parse or generate them by taking advantage of `pandas` functionality. \n",
    "- *Slice records(rows) in year of 2018*: For this exercise, we are only looking at the 911 calls in 2018; however, there is three years span in this data.\n",
    "- *Extract coordinates information from the \"location\" field*: For the later analysis, we will need to plot 911 calls to the point feature layer. However, coordinates information were recorded with location address and this format is not readable. Hence, we need to slice them out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Remove Unnecessary Columns and Empty Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priority</th>\n",
       "      <th>district</th>\n",
       "      <th>location</th>\n",
       "      <th>callDateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High</td>\n",
       "      <td>ND</td>\n",
       "      <td>400 WINSTON AV\\nBALTIMORE, MD\\n(39.349792, -76...</td>\n",
       "      <td>05/04/2016 09:58:00 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  priority district                                           location  \\\n",
       "0     High       ND  400 WINSTON AV\\nBALTIMORE, MD\\n(39.349792, -76...   \n",
       "\n",
       "             callDateTime  \n",
       "0  05/04/2016 09:58:00 PM  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice the dataframe using desired column names \n",
    "df1 = df[[\"priority\", \"district\", \"location\", \"callDateTime\"]]\n",
    "# Check the result\n",
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display all the unique values in \"priority\" field to see if there is a typo, such as \"Emergency\" was carelessly input as \"Emerg\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['High' 'Medium' 'Non-Emergency' 'Low' 'Emergency' 'Out of Service' nan]\n"
     ]
    }
   ],
   "source": [
    "# Display unique values\n",
    "print(df1.priority.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great ! It looks like there is no typo in the \"priority\" field. However, you can see that there are empty cells in this field. Let's remove them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 4007395 \n"
     ]
    }
   ],
   "source": [
    "# Drop the rows containing non value\n",
    "df2 = df1.dropna()\n",
    "# Display the remaining rows\n",
    "print(\"Total rows: {0} \".format(df2.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can see that the number of rows reduce from 4,078,343 to 4,007,395."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Derive Year, Month, and Weekday and Slice Rows in 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first slice date from the \"callDateTime\" field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priority</th>\n",
       "      <th>district</th>\n",
       "      <th>location</th>\n",
       "      <th>callDateTime</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High</td>\n",
       "      <td>ND</td>\n",
       "      <td>400 WINSTON AV\\nBALTIMORE, MD\\n(39.349792, -76...</td>\n",
       "      <td>05/04/2016 09:58:00 PM</td>\n",
       "      <td>05/04/2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  priority district                                           location  \\\n",
       "0     High       ND  400 WINSTON AV\\nBALTIMORE, MD\\n(39.349792, -76...   \n",
       "\n",
       "             callDateTime        Date  \n",
       "0  05/04/2016 09:58:00 PM  05/04/2016  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice date out and create a new field to store it\n",
    "df2[\"Date\"] = df2.callDateTime.str.slice(0,10)\n",
    "# Check the result\n",
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we slice year and month from the \"Date\" field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priority</th>\n",
       "      <th>district</th>\n",
       "      <th>location</th>\n",
       "      <th>callDateTime</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High</td>\n",
       "      <td>ND</td>\n",
       "      <td>400 WINSTON AV\\nBALTIMORE, MD\\n(39.349792, -76...</td>\n",
       "      <td>05/04/2016 09:58:00 PM</td>\n",
       "      <td>05/04/2016</td>\n",
       "      <td>05</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  priority district                                           location  \\\n",
       "0     High       ND  400 WINSTON AV\\nBALTIMORE, MD\\n(39.349792, -76...   \n",
       "\n",
       "             callDateTime        Date Month  Year  \n",
       "0  05/04/2016 09:58:00 PM  05/04/2016    05  2016  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice month out and create a new field to store it\n",
    "df2[\"Month\"] = df2.Date.str.slice(0, 2)\n",
    "# Slice year out and create a new field to store it\n",
    "df2[\"Year\"] = df2.Date.str.slice(-4,)\n",
    "# Check the result\n",
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we slice the rows in the year of 2018 and see how many rows remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018']\n",
      "Total rows: 952530 \n"
     ]
    }
   ],
   "source": [
    "# Slice rows in year of 2018\n",
    "df3 = df2[df2.Year == \"2018\"]\n",
    "# Check the result\n",
    "print(df3.Year.unique())\n",
    "# Display the remaining rows\n",
    "print(\"Total rows: {0} \".format(df3.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's convert \"Date\" filed into the `pandas` \"datatime\" data type in order to derive the weekday information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Convert to the datatime data type\n",
    "df3[\"Date\"] = pd.to_datetime(df3.Date)\n",
    "# Check the data tyoe of \"Date\" Field\n",
    "print(df3.Date.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"datetime\" format is a special data type in `pandas`, it provides lots of benefits to manage date or time. In the cell below, we are going to acquire weekday information based on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priority</th>\n",
       "      <th>district</th>\n",
       "      <th>location</th>\n",
       "      <th>callDateTime</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>High</td>\n",
       "      <td>SE</td>\n",
       "      <td>N PULASKI HY\\nBALTIMORE, MD</td>\n",
       "      <td>01/20/2018 10:20:00 AM</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>01</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  priority district                     location            callDateTime  \\\n",
       "6     High       SE  N PULASKI HY\\nBALTIMORE, MD  01/20/2018 10:20:00 AM   \n",
       "\n",
       "        Date Month  Year  Weekday  \n",
       "6 2018-01-20    01  2018        5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acquire weekay information based on \"Date\" field\n",
    "df3[\"Weekday\"] = df3.Date.dt.weekday\n",
    "# Check the result\n",
    "df3.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.4 Extract Coordinates Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look how coordinates information were recorded in the \"location\" field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6                                N PULASKI HY\\nBALTIMORE, MD\n",
       "7                                W N NORTH AV\\nBALTIMORE, MD\n",
       "3603                           E N FAYETTE ST\\nBALTIMORE, MD\n",
       "3608                           100 W EAGER ST\\nBALTIMORE, MD\n",
       "3615                           E N FAYETTE ST\\nBALTIMORE, MD\n",
       "3623                       2000 BLK BELAIR RD\\nBALTIMORE, MD\n",
       "3633                           2300 BANGER ST\\nBALTIMORE, MD\n",
       "3637                               S CAREY ST\\nBALTIMORE, MD\n",
       "3639                        0 BLK S GILMOR ST\\nBALTIMORE, MD\n",
       "3641                             FREDERICK AV\\nBALTIMORE, MD\n",
       "3642                            E N BIDDLE ST\\nBALTIMORE, MD\n",
       "3643                             300 BLOOM ST\\nBALTIMORE, MD\n",
       "3644                                1200 RAMP\\nBALTIMORE, MD\n",
       "3645                         4700 N ROGERS AV\\nBALTIMORE, MD\n",
       "3648                           N MCELDERRY ST\\nBALTIMORE, MD\n",
       "3649                               N E GAY ST\\nBALTIMORE, MD\n",
       "3650                           N MCELDERRY ST\\nBALTIMORE, MD\n",
       "3651                                ROBERT ST\\nBALTIMORE, MD\n",
       "3653                          REISTERSTOWN RD\\nBALTIMORE, MD\n",
       "3670                          PENNSYLVANIA AV\\nBALTIMORE, MD\n",
       "3671                         W GREENSPRING AV\\nBALTIMORE, MD\n",
       "3676                    400 BLLK N LUZERNE AV\\nBALTIMORE, MD\n",
       "3680                           0 E FAYETTE ST\\nBALTIMORE, MD\n",
       "3683                               S SHARP ST\\nBALTIMORE, MD\n",
       "3696                               DUNDALK AV\\nBALTIMORE, MD\n",
       "3781                                EDISON HY\\nBALTIMORE, MD\n",
       "3837                           N E LUZERNE AV\\nBALTIMORE, MD\n",
       "3840                          1100 CAMERON RD\\nBALTIMORE, MD\n",
       "3843                          0 N LAKEWOOD AV\\nBALTIMORE, MD\n",
       "3850                            0 HILLSIDE RD\\nBALTIMORE, MD\n",
       "                                 ...                        \n",
       "4078313    5400 PARK HEIGHTS AV\\nBALTIMORE, MD\\n(39.35043...\n",
       "4078314    500 W FRANKLIN ST\\nBALTIMORE, MD\\n(39.294814, ...\n",
       "4078315    300 S FULTON AV\\nBALTIMORE, MD\\n(39.284207, -7...\n",
       "4078316    300 S FULTON AV\\nBALTIMORE, MD\\n(39.284207, -7...\n",
       "4078317    1400 N MOUNT ST\\nBALTIMORE, MD\\n(39.304378, -7...\n",
       "4078318    1200 N WOODYEAR ST\\nBALTIMORE, MD\\n(39.302605,...\n",
       "4078319    2900 W LANVALE ST\\nBALTIMORE, MD\\n(39.29714, -...\n",
       "4078320    300 S SMALLWOOD ST\\nBALTIMORE, MD\\n(39.283972,...\n",
       "4078321    3700 FLEET ST\\nBALTIMORE, MD\\n(39.285656, -76....\n",
       "4078322    300 S FULTON AV\\nBALTIMORE, MD\\n(39.284207, -7...\n",
       "4078323    1400 SEVERN ST\\nBALTIMORE, MD\\n(39.275771, -76...\n",
       "4078324    5200 FAIRLAWN AV\\nBALTIMORE, MD\\n(39.342589, -...\n",
       "4078325    800 BLK S\\nBROADWAY BALTIMORE, MD\\n(39.280384,...\n",
       "4078326    200 N CULVER ST\\nBALTIMORE, MD\\n(39.288923, -7...\n",
       "4078327    2000 W BALTIMORE ST\\nBALTIMORE, MD\\n(39.288027...\n",
       "4078328    1700 BLK E FORT AV\\nBALTIMORE, MD\\n(39.268003,...\n",
       "4078329    600 S EATON ST\\nBALTIMORE, MD\\n(39.285674, -76...\n",
       "4078330    3100 MARECO AV\\nBALTIMORE, MD\\n(39.320516, -76...\n",
       "4078331    3000 GLENMORE AV\\nBALTIMORE, MD\\n(39.356613, -...\n",
       "4078332    600 W FRANKLIN ST\\nBALTIMORE, MD\\n(39.294706, ...\n",
       "4078333    200 S MONASTERY AV\\nBALTIMORE, MD\\n(39.284128,...\n",
       "4078334    2800 GIBBONS AV\\nBALTIMORE, MD\\n(39.353232, -7...\n",
       "4078335    2300 GARRETT AV\\nBALTIMORE, MD\\n(39.316537, -7...\n",
       "4078336    100 N EDGEWOOD ST\\nBALTIMORE, MD\\n(39.289102, ...\n",
       "4078337    800 MT HOLLY ST\\nBALTIMORE, MD\\n(39.296557, -7...\n",
       "4078338    500 N MILTON AV\\nBALTIMORE, MD\\n(39.29686, -76...\n",
       "4078339    1400 BLOOMFIELD AV\\nBALTIMORE, MD\\n(39.261864,...\n",
       "4078340    400 E 27TH ST\\nBALTIMORE, MD\\n(39.320935, -76....\n",
       "4078341    700 PENNSYLVANIA AV\\nBALTIMORE, MD\\n(39.295716...\n",
       "4078342    2300 ARUNAH AV\\nBALTIMORE, MD\\n(39.295586, -76...\n",
       "Name: location, Length: 952530, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the values in \"location field\"\n",
    "df3.location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can see some cells have coordinates information but some do not have. In the above code, we use `Series.str.slice` to extract date information; however, we cannot use it here as we may acquire substring of address instead of coordinates. To solve this problem, we will use `regex` module to extract coordinates information. \n",
    "\n",
    "**Regular expression** or `regex` is a special text string for describing a search pattern. We will first create a \"patter object\" and if a string matches the pattern object, it will return a match object.\n",
    "\n",
    "`pandas` has a function to extract groups from the first match of `regex` expression pattern object. Now, let's see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3637</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3641</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3643</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3644</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3645</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3670</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3671</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3676</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3683</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3781</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078313</th>\n",
       "      <td>39.35043</td>\n",
       "      <td>-76.680722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078314</th>\n",
       "      <td>39.294814</td>\n",
       "      <td>-76.623029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078315</th>\n",
       "      <td>39.284207</td>\n",
       "      <td>-76.64496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078316</th>\n",
       "      <td>39.284207</td>\n",
       "      <td>-76.64496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078317</th>\n",
       "      <td>39.304378</td>\n",
       "      <td>-76.644703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078318</th>\n",
       "      <td>39.302605</td>\n",
       "      <td>-76.639605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078319</th>\n",
       "      <td>39.29714</td>\n",
       "      <td>-76.665067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078320</th>\n",
       "      <td>39.283972</td>\n",
       "      <td>-76.651239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078321</th>\n",
       "      <td>39.285656</td>\n",
       "      <td>-76.565629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078322</th>\n",
       "      <td>39.284207</td>\n",
       "      <td>-76.64496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078323</th>\n",
       "      <td>39.275771</td>\n",
       "      <td>-76.631751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078324</th>\n",
       "      <td>39.342589</td>\n",
       "      <td>-76.685091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078325</th>\n",
       "      <td>39.280384</td>\n",
       "      <td>-76.617736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078326</th>\n",
       "      <td>39.288923</td>\n",
       "      <td>-76.674132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078327</th>\n",
       "      <td>39.288027</td>\n",
       "      <td>-76.648633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078328</th>\n",
       "      <td>39.268003</td>\n",
       "      <td>-76.590887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078329</th>\n",
       "      <td>39.285674</td>\n",
       "      <td>-76.565206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078330</th>\n",
       "      <td>39.320516</td>\n",
       "      <td>-76.574568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078331</th>\n",
       "      <td>39.356613</td>\n",
       "      <td>-76.557711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078332</th>\n",
       "      <td>39.294706</td>\n",
       "      <td>-76.626111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078333</th>\n",
       "      <td>39.284128</td>\n",
       "      <td>-76.680721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078334</th>\n",
       "      <td>39.353232</td>\n",
       "      <td>-76.564689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078335</th>\n",
       "      <td>39.316537</td>\n",
       "      <td>-76.601164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078336</th>\n",
       "      <td>39.289102</td>\n",
       "      <td>-76.677418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078337</th>\n",
       "      <td>39.296557</td>\n",
       "      <td>-76.679878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078338</th>\n",
       "      <td>39.29686</td>\n",
       "      <td>-76.582152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078339</th>\n",
       "      <td>39.261864</td>\n",
       "      <td>-76.666699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078340</th>\n",
       "      <td>39.320935</td>\n",
       "      <td>-76.610677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078341</th>\n",
       "      <td>39.295716</td>\n",
       "      <td>-76.625104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078342</th>\n",
       "      <td>39.295586</td>\n",
       "      <td>-76.653457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>952530 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1\n",
       "6              NaN          NaN\n",
       "7              NaN          NaN\n",
       "3603           NaN          NaN\n",
       "3608           NaN          NaN\n",
       "3615           NaN          NaN\n",
       "3623           NaN          NaN\n",
       "3633           NaN          NaN\n",
       "3637           NaN          NaN\n",
       "3639           NaN          NaN\n",
       "3641           NaN          NaN\n",
       "3642           NaN          NaN\n",
       "3643           NaN          NaN\n",
       "3644           NaN          NaN\n",
       "3645           NaN          NaN\n",
       "3648           NaN          NaN\n",
       "3649           NaN          NaN\n",
       "3650           NaN          NaN\n",
       "3651           NaN          NaN\n",
       "3653           NaN          NaN\n",
       "3670           NaN          NaN\n",
       "3671           NaN          NaN\n",
       "3676           NaN          NaN\n",
       "3680           NaN          NaN\n",
       "3683           NaN          NaN\n",
       "3696           NaN          NaN\n",
       "3781           NaN          NaN\n",
       "3837           NaN          NaN\n",
       "3840           NaN          NaN\n",
       "3843           NaN          NaN\n",
       "3850           NaN          NaN\n",
       "...            ...          ...\n",
       "4078313   39.35043   -76.680722\n",
       "4078314  39.294814   -76.623029\n",
       "4078315  39.284207    -76.64496\n",
       "4078316  39.284207    -76.64496\n",
       "4078317  39.304378   -76.644703\n",
       "4078318  39.302605   -76.639605\n",
       "4078319   39.29714   -76.665067\n",
       "4078320  39.283972   -76.651239\n",
       "4078321  39.285656   -76.565629\n",
       "4078322  39.284207    -76.64496\n",
       "4078323  39.275771   -76.631751\n",
       "4078324  39.342589   -76.685091\n",
       "4078325  39.280384   -76.617736\n",
       "4078326  39.288923   -76.674132\n",
       "4078327  39.288027   -76.648633\n",
       "4078328  39.268003   -76.590887\n",
       "4078329  39.285674   -76.565206\n",
       "4078330  39.320516   -76.574568\n",
       "4078331  39.356613   -76.557711\n",
       "4078332  39.294706   -76.626111\n",
       "4078333  39.284128   -76.680721\n",
       "4078334  39.353232   -76.564689\n",
       "4078335  39.316537   -76.601164\n",
       "4078336  39.289102   -76.677418\n",
       "4078337  39.296557   -76.679878\n",
       "4078338   39.29686   -76.582152\n",
       "4078339  39.261864   -76.666699\n",
       "4078340  39.320935   -76.610677\n",
       "4078341  39.295716   -76.625104\n",
       "4078342  39.295586   -76.653457\n",
       "\n",
       "[952530 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Create the pattern object\n",
    "p = re.compile(r\".*\\n.*\\n\\((.*),(.*)\\)\")\n",
    "\n",
    "# Return a new dataframe with columns of capture groups\n",
    "df4 = df3.location.str.extract(p, expand = False)\n",
    "\n",
    "# Check the result\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can see that a new dataframe was created and two columns were added to it. The column \"0\" represents the first match group, which is \"latitude\", the column \"1' represents the second match group, which is \"longitude\". If the cells in \"location\" field do not contain coordinates, the \"NaN\" value will be returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next,let's rename the columns to make sense of them, join it back to the original dataframe, and remove rows containing empty values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Latitude Longitude\n",
       "6         NaN       NaN\n",
       "7         NaN       NaN\n",
       "3603      NaN       NaN\n",
       "3608      NaN       NaN\n",
       "3615      NaN       NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the columns' names\n",
    "df4.rename(columns = {0: \"Latitude\", 1 : \"Longitude\"}, inplace = True)\n",
    "# Check the result\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priority</th>\n",
       "      <th>district</th>\n",
       "      <th>location</th>\n",
       "      <th>callDateTime</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>High</td>\n",
       "      <td>SE</td>\n",
       "      <td>N PULASKI HY\\nBALTIMORE, MD</td>\n",
       "      <td>01/20/2018 10:20:00 AM</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>01</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>High</td>\n",
       "      <td>SW</td>\n",
       "      <td>W N NORTH AV\\nBALTIMORE, MD</td>\n",
       "      <td>01/20/2018 08:37:00 AM</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>01</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>Medium</td>\n",
       "      <td>CD</td>\n",
       "      <td>E N FAYETTE ST\\nBALTIMORE, MD</td>\n",
       "      <td>01/01/2018 01:56:00 AM</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>01</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Low</td>\n",
       "      <td>CD</td>\n",
       "      <td>100 W EAGER ST\\nBALTIMORE, MD</td>\n",
       "      <td>01/05/2018 02:16:00 PM</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>01</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>Medium</td>\n",
       "      <td>CD</td>\n",
       "      <td>E N FAYETTE ST\\nBALTIMORE, MD</td>\n",
       "      <td>01/09/2018 06:26:00 PM</td>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>01</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     priority district                       location            callDateTime  \\\n",
       "6        High       SE    N PULASKI HY\\nBALTIMORE, MD  01/20/2018 10:20:00 AM   \n",
       "7        High       SW    W N NORTH AV\\nBALTIMORE, MD  01/20/2018 08:37:00 AM   \n",
       "3603   Medium       CD  E N FAYETTE ST\\nBALTIMORE, MD  01/01/2018 01:56:00 AM   \n",
       "3608      Low       CD  100 W EAGER ST\\nBALTIMORE, MD  01/05/2018 02:16:00 PM   \n",
       "3615   Medium       CD  E N FAYETTE ST\\nBALTIMORE, MD  01/09/2018 06:26:00 PM   \n",
       "\n",
       "           Date Month  Year  Weekday Latitude Longitude  \n",
       "6    2018-01-20    01  2018        5      NaN       NaN  \n",
       "7    2018-01-20    01  2018        5      NaN       NaN  \n",
       "3603 2018-01-01    01  2018        0      NaN       NaN  \n",
       "3608 2018-01-05    01  2018        4      NaN       NaN  \n",
       "3615 2018-01-09    01  2018        1      NaN       NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join columns from df4 to df3\n",
    "df5 = df3.join(df4)\n",
    "# Check the result\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priority</th>\n",
       "      <th>district</th>\n",
       "      <th>location</th>\n",
       "      <th>callDateTime</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42962</th>\n",
       "      <td>Medium</td>\n",
       "      <td>NW</td>\n",
       "      <td>3600 FORDS LN\\nBALTIMORE, MD\\n(39.359715, -76....</td>\n",
       "      <td>01/13/2018 07:45:00 AM</td>\n",
       "      <td>2018-01-13</td>\n",
       "      <td>01</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>39.359715</td>\n",
       "      <td>-76.697044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42963</th>\n",
       "      <td>Low</td>\n",
       "      <td>NW</td>\n",
       "      <td>3600 PLATEAU AV\\nBALTIMORE, MD\\n(39.333044, -7...</td>\n",
       "      <td>01/23/2018 06:34:00 PM</td>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>01</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>39.333044</td>\n",
       "      <td>-76.699367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42964</th>\n",
       "      <td>Medium</td>\n",
       "      <td>CD</td>\n",
       "      <td>300 W PRESTON ST\\nBALTIMORE, MD\\n(39.301803, -...</td>\n",
       "      <td>01/11/2018 03:43:00 PM</td>\n",
       "      <td>2018-01-11</td>\n",
       "      <td>01</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>39.301803</td>\n",
       "      <td>-76.622675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42965</th>\n",
       "      <td>High</td>\n",
       "      <td>SD</td>\n",
       "      <td>1000 W PATAPSCO AV\\nBALTIMORE, MD\\n(39.246726,...</td>\n",
       "      <td>01/09/2018 08:38:00 AM</td>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>01</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>39.246726</td>\n",
       "      <td>-76.636095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42966</th>\n",
       "      <td>Medium</td>\n",
       "      <td>NW</td>\n",
       "      <td>5500 JONQUIL AV\\nBALTIMORE, MD\\n(39.349911, -7...</td>\n",
       "      <td>01/15/2018 12:18:00 AM</td>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>01</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>39.349911</td>\n",
       "      <td>-76.686644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      priority district                                           location  \\\n",
       "42962   Medium       NW  3600 FORDS LN\\nBALTIMORE, MD\\n(39.359715, -76....   \n",
       "42963      Low       NW  3600 PLATEAU AV\\nBALTIMORE, MD\\n(39.333044, -7...   \n",
       "42964   Medium       CD  300 W PRESTON ST\\nBALTIMORE, MD\\n(39.301803, -...   \n",
       "42965     High       SD  1000 W PATAPSCO AV\\nBALTIMORE, MD\\n(39.246726,...   \n",
       "42966   Medium       NW  5500 JONQUIL AV\\nBALTIMORE, MD\\n(39.349911, -7...   \n",
       "\n",
       "                 callDateTime       Date Month  Year  Weekday   Latitude  \\\n",
       "42962  01/13/2018 07:45:00 AM 2018-01-13    01  2018        5  39.359715   \n",
       "42963  01/23/2018 06:34:00 PM 2018-01-23    01  2018        1  39.333044   \n",
       "42964  01/11/2018 03:43:00 PM 2018-01-11    01  2018        3  39.301803   \n",
       "42965  01/09/2018 08:38:00 AM 2018-01-09    01  2018        1  39.246726   \n",
       "42966  01/15/2018 12:18:00 AM 2018-01-15    01  2018        0  39.349911   \n",
       "\n",
       "         Longitude  \n",
       "42962   -76.697044  \n",
       "42963   -76.699367  \n",
       "42964   -76.622675  \n",
       "42965   -76.636095  \n",
       "42966   -76.686644  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the rows containing NaN\n",
    "df5.dropna(inplace = True)\n",
    "# Check the result\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are going to display the data type of each column and convert columns' data types to the desired format. \n",
    "\n",
    "We would like \"Month\" and \"Year\" in integer and \"Latitude\" and \"Longitude\" in float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "priority                object\n",
       "district                object\n",
       "location                object\n",
       "callDateTime            object\n",
       "Date            datetime64[ns]\n",
       "Month                   object\n",
       "Year                    object\n",
       "Weekday                  int64\n",
       "Latitude                object\n",
       "Longitude               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display columns' data types\n",
    "df5.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "priority                object\n",
       "district                object\n",
       "location                object\n",
       "callDateTime            object\n",
       "Date            datetime64[ns]\n",
       "Month                    int32\n",
       "Year                     int32\n",
       "Weekday                  int64\n",
       "Latitude               float64\n",
       "Longitude              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to desired data types\n",
    "df6 = df5.astype({\"Month\":int, \"Year\":int,\n",
    "                  \"Latitude\":float, \"Longitude\":float})\n",
    "# Check the result\n",
    "df6.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent!! Now the data is clean and allows us to do the analysis. Let's see how many rows are remained and export this clean data to a csv file for later usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 701856 \n"
     ]
    }
   ],
   "source": [
    "# Display the remaining rows\n",
    "print(\"Total rows: {0} \".format(df6.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a new csv file\n",
    "df6.to_csv(\"911_calls_in_2018.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recaping from the above cells, you took advantage of `pandas` module to read and modify your data and `regex` module to extract coordinates information in an efficient manner. The file size reduced from about 530 MB to 90 MB, this will allow ArcGIS software read and proceed it easier and faster. However, in the age of big data, this file size is quite small. What if you want to read a file with larger size in ArcGIS software? Even if ArcGIS can read it, it might still be strenous for ArrGIS to process. Therefore, it is better off to keep working with programming language. And this is where `ArcPy` comes into play. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells, we will take advantage of `ArcPy` Python site package to perform data analysis. `ArcPy` provides a rich modules and functions to carry out geographic data analysis, data conversion, data management, and map automation. \n",
    "\n",
    "For this exercise, we are going to perform two types of geospatial analysis.\n",
    "> 1. Spatial Join Analysis\n",
    "2. Hotspot Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Set Up Working Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we first import `ArcPy` module and then set up our wokring environment. The working environment is where the analysis output will be stored and managed, we typically usa a file geodatabase as the working environment. We can also set the properties of the working environment, such as allow file overwritting and coordinate system of analysis output. These settings can help us work faster and easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "\n",
    "# Set up current working directory\n",
    "current_dir = r\"C:\\Users\\user\\Documents\\ArcGIS\\Projects\"\n",
    "# Set up your workspace\n",
    "arcpy.env.workspace = current_dir + r\"\\Assignment 4\\Assignment 4.gdb\"\n",
    "# Allow file overwritting\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Set the workspace outputCoordinateSystem environment\n",
    "# This setting will automatically convert your analysis output to this projected system\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(6487)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used for analysis includes **911 calls**, **TIGER/Line Maryland census tract**, and **Baltimore district**. To use these data, we need to perform some tasks first. \n",
    "\n",
    "- *Plot 911 calls* to point feature class: The 911 calls data is now stored in the csv file we created above. To use it for analysis, we need to create a point feature class of 911 calls data.\n",
    "- *Select out the study area*: Since TIGHER/Line census tract can only be downloaded by state, we need to perform selection analysis to select our study area- Baltimore county. \n",
    "- *Clip 911 calls to the study area*: There might be some typos of coordinate values that lead to the 911 calls fall oustide the study area, so we will perform clip analysis to ensure all the 911 calls are wihtin the study area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.2.1 Plot 911 Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAD_1983_2011_StatePlane_Maryland_FIPS_1900\n"
     ]
    }
   ],
   "source": [
    "# Set path to input file and create output file name\n",
    "# The input file is the csv file we created above\n",
    "input_file = current_dir + r\"\\Assignment 4 _script\\Stats19-Data1979-2004\\911_calls_in_2018.csv\"\n",
    "output_file = \"Calls_2018\"\n",
    "\n",
    "# Run the \"XY Table To Point\" tool\n",
    "arcpy.management.XYTableToPoint(input_file, output_file, \n",
    "                                x_field = \"Longitude\", y_field = \"Latitude\")\n",
    "\n",
    "# Check the coordinate system\n",
    "print(arcpy.Describe(output_file).Spatialreference.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.2.2 Select Out the Study Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert **TIGER/Line Maryland census tract shapefile** to a polygon feature class, let's first look the fields' names in the census tract shapefile.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID\n",
      "Shape\n",
      "STATEFP\n",
      "COUNTYFP\n",
      "TRACTCE\n",
      "GEOID\n",
      "NAME\n",
      "NAMELSAD\n",
      "MTFCC\n",
      "FUNCSTAT\n",
      "ALAND\n",
      "AWATER\n",
      "INTPTLAT\n",
      "INTPTLON\n"
     ]
    }
   ],
   "source": [
    "# Define file's name\n",
    "input_file = current_dir + r\"\\Assignment 4\\Data\\Census_Tract\\tl_2018_24_tract.shp\"\n",
    "\n",
    "# Read the fields containing in the shapefile and diplay their names using the \"ListFields\" function\n",
    "fields = arcpy.ListFields(input_file)\n",
    "for field in fields:\n",
    "    print(field.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNTYFP:033\n"
     ]
    }
   ],
   "source": [
    "# Read the value of the \"COUNTYFP\" field to verify the fip code scheme\n",
    "rows = arcpy.SearchCursor(input_file, fields = \"COUNTYFP\")\n",
    "for row in rows:\n",
    "    print(\"COUNTYFP:{0}\".format(row.getValue(\"COUNTYFP\")))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAD_1983_2011_StatePlane_Maryland_FIPS_1900\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "path = current_dir + r\"\\Assignment 4\\Assignment 4.gdb\"\n",
    "output_feature = \"Baltimore_CT\"\n",
    "# Run the \"Feature Class to Feature Class\" tool and only extract the features where their \"COUNTYFP\" matches Baltimore's Fip\n",
    "arcpy.FeatureClassToFeatureClass_conversion(input_file, path, output_feature, \n",
    "                                            \"COUNTYFP='510'\")\n",
    "# Check the coordinate system\n",
    "print(arcpy.Describe(output_feature).SpatialReference.Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert **Baltimore district shapefile** to a polygon feature class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAD_1983_2011_StatePlane_Maryland_FIPS_1900\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "input_file = current_dir + r\"\\Assignment 4\\Data\\Legislative_Districts\\Legislative_Districts.shp\"\n",
    "path = current_dir + r\"\\Assignment 4\\Assignment 4.gdb\"\n",
    "output_feature = \"Baltimore_district\"\n",
    "\n",
    "# Run the \"Feature Class to Feature Class\" tool\n",
    "arcpy.FeatureClassToFeatureClass_conversion(input_file, path, output_feature)\n",
    "\n",
    "# Check the coordinate system\n",
    "print(arcpy.Describe(output_feature).SpatialReference.Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.2.3 Clip 911 Calls to the Study Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAD_1983_2011_StatePlane_Maryland_FIPS_1900\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "input_feature = \"Calls_2018\"\n",
    "output_feature = \"Baltimore_calls_2018\"\n",
    "cutter = \"Baltimore_CT\"\n",
    "\n",
    "# Run the \"Clip\" tool\n",
    "arcpy.Clip_analysis(input_feature, cutter, output_feature)\n",
    "\n",
    "# Check the coordinate system\n",
    "print(arcpy.Describe(output_feature).SpatialReference.Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Perform Spatial Join Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we are interested in answering two questions. The questions are as the following:\n",
    "> 1. Identify which district has the highest number of 911 calls.  \n",
    "2. Identify which month and weekday has the highest number of 911 calls in each district."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Identify which district has the highest number of 911 calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question, we have to spatial join the \"911 calls\" point feature class into the \"Baltimore\" polygon feature class. Then, we will see how many calls are there in each district and display the name of district having the highest number and its total number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\user\\\\Documents\\\\ArcGIS\\\\Projects\\\\Assignment 4\\\\Assignment 4.gdb\\\\Total_calls_district'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define files' names\n",
    "target_feature = \"Baltimore_district\"\n",
    "join_feature = \"Baltimore_calls_2018\"\n",
    "output_feature = \"Total_calls_district\"\n",
    "\n",
    "# Run the sptail join tool to identify total accident number in each county\n",
    "arcpy.SpatialJoin_analysis(target_feature, join_feature, \n",
    "                           output_feature, match_option = \"COMPLETELY_CONTAINS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID_1 : OID\n",
      "Shape : Geometry\n",
      "Join_Count : Integer\n",
      "TARGET_FID : Integer\n",
      "OBJECTID : Integer\n",
      "AREA_NAME : String\n",
      "AREA_NMBR : Integer\n",
      "URL : String\n",
      "ShapeSTAre : Double\n",
      "priority : String\n",
      "district : String\n",
      "location : String\n",
      "callDateTime : String\n",
      "Date : Date\n",
      "Month : Integer\n",
      "Year : Integer\n",
      "Weekday : Integer\n",
      "Latitude : Double\n",
      "Longitude : Double\n",
      "Shape_Length : Double\n",
      "Shape_Area : Double\n"
     ]
    }
   ],
   "source": [
    "# Print out all the field names and their type in the output feature\n",
    "# Use the \"ListFields\" function\n",
    "fields = arcpy.ListFields(output_feature)\n",
    "\n",
    "for field in fields:\n",
    "    print(field.name,\":\", field.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'State Legislative District 40' has the highest number of 911 calls in 2018, the total count is 163423\n"
     ]
    }
   ],
   "source": [
    "# Using search cursor to iterate through the feature class and\n",
    "# display the name and total accident number of the county has the highest total accidents \n",
    "rows = arcpy.SearchCursor(output_feature, fields = \"Join_Count; AREA_NAME\", \n",
    "                          sort_fields = \"Join_Count D\")\n",
    "for row in rows:\n",
    "    print(\"'{0}' {1} {2}\".format(\n",
    "        row.getValue(\"AREA_NAME\"),\n",
    "        \"has the highest number of 911 calls in 2018, the total count is\",\n",
    "        row.getValue(\"Join_Count\")))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Identify which month and weekday had the highest number of 911 calls in each district."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question, we will include \"Weekday\", and \"Month\" information to our output table so that we can see which month and weekday had the highest number of 911 calls in each district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define files' names\n",
    "target_feature = \"Baltimore_district\"\n",
    "join_feature = \"Baltimore_calls_2018\"\n",
    "output_feature = \"Types_calls_district\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat the required FieldMap and FieldMappings objects\n",
    "fm_month = arcpy.FieldMap()\n",
    "fm_district = arcpy.FieldMap()\n",
    "fm_weekday = arcpy.FieldMap()\n",
    "fms = arcpy.FieldMappings()\n",
    "\n",
    "# Get each field name from their original file\n",
    "month = \"MONTH\"\n",
    "district = \"AREA_NAME\"\n",
    "weekday = \"Weekday\"\n",
    "\n",
    "# Add fields to their corresponding FieldMap objects\n",
    "fm_month.addInputField(join_feature, month)\n",
    "fm_weekday.addInputField(join_feature, weekday)\n",
    "fm_district.addInputField(target_feature, district)\n",
    "\n",
    "# Get the output field's properties as a field object\n",
    "# Rename the field and pass the updated field object back into the field map\n",
    "district_name = fm_district.outputField\n",
    "district_name.name = \"District\"\n",
    "district_name.aliasName = \"District\"\n",
    "fm_district.outputField = district_name\n",
    "\n",
    "# Set merge rule to FieldMaps\n",
    "fm_month.mergeRule = \"Mode\"\n",
    "fm_weekday.mergeRule = \"Mode\"\n",
    "\n",
    "# Add the FieldMap objects to the FieldMappings object\n",
    "fms.addFieldMap(fm_district)\n",
    "fms.addFieldMap(fm_weekday)\n",
    "fms.addFieldMap(fm_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\user\\\\Documents\\\\ArcGIS\\\\Projects\\\\Assignment 4\\\\Assignment 4.gdb\\\\Types_calls_district'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the \"Spatial Join\" tool with Fieldmappings object\n",
    "arcpy.SpatialJoin_analysis(target_feature, join_feature, \n",
    "                           output_feature, match_option = \"COMPLETELY_CONTAINS\", \n",
    "                           field_mapping = fms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID\n",
      "Shape\n",
      "Join_Count\n",
      "TARGET_FID\n",
      "District\n",
      "Weekday\n",
      "Month\n",
      "Shape_Length\n",
      "Shape_Area\n"
     ]
    }
   ],
   "source": [
    "# Display fields' names of output feature\n",
    "for field in arcpy.ListFields(output_feature):\n",
    "    print(field.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month: 5 has the highest number of 911 calls in 'State Legislative District 40'.\n",
      "Month: 5 has the highest number of 911 calls in 'State Legislative District 41'.\n",
      "Month: 5 has the highest number of 911 calls in 'State Legislative District 43'.\n",
      "Month: 12 has the highest number of 911 calls in 'State Legislative District 44A'.\n",
      "Month: 5 has the highest number of 911 calls in 'State Legislative District 45'.\n",
      "Month: 8 has the highest number of 911 calls in 'State Legislative District 46'.\n"
     ]
    }
   ],
   "source": [
    "# Using the \"SearchCursor\" function to iterate through the feature class and\n",
    "# display county name and the month having the highest occurence of accidents in this county \n",
    "rows = arcpy.SearchCursor(output_feature, \n",
    "                          fields = \"District; Month\")\n",
    "for row in rows:\n",
    "    print(\"{0} {1} {2} '{3}'.\".format(\n",
    "        \"Month:\",\n",
    "        row.getValue(\"Month\"),\n",
    "        \"has the highest number of 911 calls in\",\n",
    "        row.getValue(\"District\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekday: 4 has the highest number of 911 calls in 'State Legislative District 40'.\n",
      "Weekday: 4 has the highest number of 911 calls in 'State Legislative District 41'.\n",
      "Weekday: 4 has the highest number of 911 calls in 'State Legislative District 43'.\n",
      "Weekday: 4 has the highest number of 911 calls in 'State Legislative District 44A'.\n",
      "Weekday: 4 has the highest number of 911 calls in 'State Legislative District 45'.\n",
      "Weekday: 4 has the highest number of 911 calls in 'State Legislative District 46'.\n"
     ]
    }
   ],
   "source": [
    "# Using the \"SearchCursor\" function to iterate through the feature class and\n",
    "# display county name and the weekday having the highest occurence of accidents in this county \n",
    "rows = arcpy.SearchCursor(output_feature, \n",
    "                          fields = \"District; Weekday\")\n",
    "for row in rows:\n",
    "    print(\"{0} {1} {2} '{3}'.\".format(\n",
    "        \"Weekday:\",\n",
    "        row.getValue(\"Weekday\"),\n",
    "        \"has the highest number of 911 calls in\",\n",
    "        row.getValue(\"District\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Perform Hotspot Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells, we are going to perform hotspot analysis to create the hotspot map of high priority 911 calls in Baltimore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Select out high-priority 911 Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file's name\n",
    "input_feature = \"Baltimore_calls_2018\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\user\\\\Documents\\\\ArcGIS\\\\Projects\\\\Assignment 4\\\\Assignment 4.gdb\\\\High_priority_calls'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define SQL expression\n",
    "where_clause = \"priority = 'High'\"\n",
    "\n",
    "# Run the \"Select Layer by Attribute tool\" to select out accidents with deaths \n",
    "High_priority_calls = arcpy.SelectLayerByAttribute_management(input_feature, \"NEW_SELECTION\", \n",
    "                                                              where_clause)\n",
    "\n",
    "# Export to a new feature class using the \"Copy Features\" tool\n",
    "arcpy.CopyFeatures_management(High_priority_calls, 'High_priority_calls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Using census tract as the basic unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "input_feature = \"High_priority_calls\"\n",
    "output_feature = \"Hotspot_hp_calls_CT\"\n",
    "Aggregating_Polygon = \"Baltimore_CT\"\n",
    "# Define output folder \n",
    "output_folder = current_dir + r\"\\Assignment 4\\Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\user\\\\Documents\\\\ArcGIS\\\\Projects\\\\Assignment 4\\\\Data'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the \"Optimized hotspot analysis\" tool with census tract as aggregating polygon\n",
    "arcpy.OptimizedHotSpotAnalysis_stats(input_feature, output_feature, \n",
    "                                     \"#\", \"COUNT_INCIDENTS_WITHIN_AGGREGATION_POLYGONS\", \n",
    "                                     \"#\", Aggregating_Polygon, \"#\", \"#\", \"#\")\n",
    "\n",
    "# Save the output file as a shapefile\n",
    "arcpy.FeatureClassToShapefile_conversion(output_feature, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.3 Using fishnet grid as the basic unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define outout feature class name\n",
    "output_feature = \"Hotspot_hp_calls_Fishnetgrid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\user\\\\Documents\\\\ArcGIS\\\\Projects\\\\Assignment 4\\\\Data'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the \"Optimized hotspot analysis\" tool with fishnet grid as aggregating polygon\n",
    "arcpy.OptimizedHotSpotAnalysis_stats(input_feature, \n",
    "                                     output_feature, \n",
    "                                     \"#\", \"COUNT_INCIDENTS_WITHIN_FISHNET_POLYGONS\", \n",
    "                                     \"#\", \"#\", \"#\", \"#\", \"#\")\n",
    "\n",
    "# Save the output file as a shapefile\n",
    "arcpy.FeatureClassToShapefile_conversion(output_feature, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have finished hotspot analysis and next we are about to visualize the results using function provided by `ArcGIS API for Python`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Result Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ArcGIS API for Python` is a Python library for working with maps and geospatial data, powered by web GIS. It not only provides a rich set of functions for geospatial analysis but also allows us to manage and organize our GIS content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about `ArcGIS API for Python`, please refer to this [website](https://developers.arcgis.com/python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure to visualize the results involves two steps:\n",
    "- Upload datasets to your GIS content and publish them as feature layer.\n",
    "- Create a basemap and add the feature layers on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.1 Upload datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import \"GIS\" Object from the \"gis\" module within `ArcGIS API for Python`. Then we create a GIS object by passing in login credential. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GIS object\n",
    "from arcgis.gis import GIS\n",
    "# Import display function from IPython module in order to display GIS content later\n",
    "from IPython.display import display\n",
    "# Create a GIS object\n",
    "gis = GIS(\"Pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the properties of the file that is going to be uploaded\n",
    "CT_hot_properties = {\n",
    "    \"title\" : \"Hotspot_hp_calls_CT\",\n",
    "    \"type\" : \"Shapefile\",\n",
    "    \"tags\" : \"Hotspot, High Priority Calls, Baltimore\",\n",
    "    \"description\":\"{0}{1}{2}\".format(\"This hotspot map was created for course usage.\", \n",
    "                                     \"This map displays hotspot of high priority 911 calls in Baltimore.\",\n",
    "                                     \"Census tracts are used as the geographic unit for hotspot analysis.\")\n",
    "}             \n",
    "\n",
    "# Define the path of the file\n",
    "upload_file = current_dir + r\"\\Assignment 4\\Data\\Hotspot_hp_calls_CT.zip\"\n",
    "\n",
    "# Add the file to the GIS content, which is your ArcGIS Online content\n",
    "CT_hotspot = gis.content.add(item_properties = CT_hot_properties, data = upload_file)\n",
    "\n",
    "# Publish the file to a feature layer\n",
    "CT_hotspot_item = CT_hotspot.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the properties of the file that is going to be uploaded\n",
    "FG_hot_properties = {\n",
    "    \"title\" : \"Hotspot_hp_calls_FG\",\n",
    "    \"type\" : \"Shapefile\",\n",
    "    \"tags\" : \"Hotspot, High Priority Calls, Baltimore\",\n",
    "    \"description\":\"{0}{1}{2}\".format(\"This hotspot map was created for course usage.\", \n",
    "                                     \"This map displays hotspot of high priority 911 calls in Baltimore.\",\n",
    "                                     \"Fishnet grids are used as the geographic unit for hotspot analysis.\")\n",
    "}             \n",
    "\n",
    "# Define the path of the file\n",
    "upload_file = current_dir + r\"\\Assignment 4\\Data\\Hotspot_hp_calls_Fishnetgrid.zip\"\n",
    "\n",
    "# Add the file to the GIS content, which is your ArcGIS Online content\n",
    "FG_hotspot = gis.content.add(item_properties = FG_hot_properties, data = upload_file)\n",
    "\n",
    "# Publish the file to a feature layer\n",
    "FG_hotspot_item = FG_hotspot.publish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have finished uploading and publishing the datasets. In the cell below, let's search them in the GIS content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"item_container\" style=\"height: auto; overflow: hidden; border: 1px solid #cfcfcf; border-radius: 2px; background: #f6fafa; line-height: 1.21429em; padding: 10px;\">\n",
       "                    <div class=\"item_left\" style=\"width: 210px; float: left;\">\n",
       "                       <a href='https://www.arcgis.com//home/item.html?id=b7b3712c3fc04511a99741b30be5a389' target='_blank'>\n",
       "                        <img src='http://static.arcgis.com/images/desktopapp.png' class=\"itemThumbnail\">\n",
       "                       </a>\n",
       "                    </div>\n",
       "\n",
       "                    <div class=\"item_right\"     style=\"float: none; width: auto; overflow: hidden;\">\n",
       "                        <a href='https://www.arcgis.com//home/item.html?id=b7b3712c3fc04511a99741b30be5a389' target='_blank'><b>Hotspot_hp_calls_FG</b>\n",
       "                        </a>\n",
       "                        <br/><img src='https://www.arcgis.com//home/js/jsapi/esri/css/images/item_type_icons/featureshosted16.png' style=\"vertical-align:middle;\">Feature Layer Collection by lin00297_UMN\n",
       "                        <br/>Last Modified: May 02, 2019\n",
       "                        <br/>0 comments, 0 views\n",
       "                    </div>\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<Item title:\"Hotspot_hp_calls_FG\" type:Feature Layer Collection owner:lin00297_UMN>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"item_container\" style=\"height: auto; overflow: hidden; border: 1px solid #cfcfcf; border-radius: 2px; background: #f6fafa; line-height: 1.21429em; padding: 10px;\">\n",
       "                    <div class=\"item_left\" style=\"width: 210px; float: left;\">\n",
       "                       <a href='https://www.arcgis.com//home/item.html?id=69c1876660c1435b99e75b97f470e3d7' target='_blank'>\n",
       "                        <img src='http://static.arcgis.com/images/desktopapp.png' class=\"itemThumbnail\">\n",
       "                       </a>\n",
       "                    </div>\n",
       "\n",
       "                    <div class=\"item_right\"     style=\"float: none; width: auto; overflow: hidden;\">\n",
       "                        <a href='https://www.arcgis.com//home/item.html?id=69c1876660c1435b99e75b97f470e3d7' target='_blank'><b>Hotspot_hp_calls_CT</b>\n",
       "                        </a>\n",
       "                        <br/><img src='https://www.arcgis.com//home/js/jsapi/esri/css/images/item_type_icons/featureshosted16.png' style=\"vertical-align:middle;\">Feature Layer Collection by lin00297_UMN\n",
       "                        <br/>Last Modified: May 02, 2019\n",
       "                        <br/>0 comments, 0 views\n",
       "                    </div>\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<Item title:\"Hotspot_hp_calls_CT\" type:Feature Layer Collection owner:lin00297_UMN>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Search feature layers contain \"Hotspot_hp_calls\"\n",
    "search_result = gis.content.search(query= \"Hotspot_hp_calls\", \n",
    "                                   item_type = \"Feature Layer\")\n",
    "\n",
    "# Display them\n",
    "for layer in search_result:\n",
    "    display(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that both feature layers are \"Feature Layer Collection\" item. Since this item is a Feature Layer Collection, accessing the `layers` property will give us a list of `FeatureLayer` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<FeatureLayer url:\"https://services.arcgis.com/8df8p0NlLFEShl0r/arcgis/rest/services/Hotspot_hp_calls_Fishnetgrid/FeatureServer/0\">] \n",
      " [<FeatureLayer url:\"https://services.arcgis.com/8df8p0NlLFEShl0r/arcgis/rest/services/Hotspot_hp_calls_CT/FeatureServer/0\">]\n"
     ]
    }
   ],
   "source": [
    "# Read as feature layer instead feature layer collection\n",
    "# This is useful if you want to read the properties of your files\n",
    "hotspot_hp_calls_FG = search_result[0].layers\n",
    "hotspot_hp_calls_CT = search_result[1].layers\n",
    "print(hotspot_hp_calls_FG,\"\\n\",hotspot_hp_calls_CT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us take a closer look at the properties of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"xmin\": -8539554.469651511,\n",
       "  \"ymin\": 4750219.9411982335,\n",
       "  \"xmax\": -8519137.288212582,\n",
       "  \"ymax\": 4775178.12296056,\n",
       "  \"spatialReference\": {\n",
       "    \"wkid\": 102100,\n",
       "    \"latestWkid\": 3857\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the extent of the \"hotspot_hp_calls_FG\"\n",
    "hotspot_hp_calls_FG[0].properties.extent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The properties field on a `FeatureLayer` object provides a dictionary representation of all its properties. However you can access individual properties as fields as well.\n",
    "\n",
    "Now, we want to know the names of fields present in these layers because we want to classify our map based on the desired fields. To check the names of fields, we can call the `fields` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID\n",
      "SOURCE_ID\n",
      "JOIN_COUNT\n",
      "Shape_Leng\n",
      "Shape_Area\n",
      "GiZScore\n",
      "GiPValue\n",
      "NNeighbors\n",
      "Gi_Bin\n",
      "Shape__Area\n",
      "Shape__Length\n"
     ]
    }
   ],
   "source": [
    "for field in hotspot_hp_calls_FG[0].properties.fields:\n",
    "    print(field[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID\n",
      "SOURCE_ID\n",
      "Join_Count\n",
      "Shape_Leng\n",
      "Shape_Area\n",
      "GiZScore\n",
      "GiPValue\n",
      "NNeighbors\n",
      "Gi_Bin\n",
      "Shape__Area\n",
      "Shape__Length\n"
     ]
    }
   ],
   "source": [
    "for field in hotspot_hp_calls_CT[0].properties.fields:\n",
    "    print(field[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we have all the names of fields and we will use \"Gi_Bin\" as our classified field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2.5.2 Create a basemap and add the feature layers on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gis` module provides opportunity to create a map widget centered at the declared location by using `map` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce6488d7d5a4c5fbbea4218b0f072f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MapView(layout=Layout(height='400px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a map widget centered at Baltimore as basemap\n",
    "map_for_FG = gis.map(location=\"Baltimore\")\n",
    "map_for_FG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac9c08d8ee24c6388fe805e80876385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MapView(layout=Layout(height='400px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a map widget centered at Baltimore as basemap.\n",
    "map_for_CT = gis.map(location=\"Baltimore\")\n",
    "map_for_CT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This map widge also provides us a list of basemap style options. We can use `basemap` method to see all the available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dark-gray',\n",
       " 'dark-gray-vector',\n",
       " 'gray',\n",
       " 'gray-vector',\n",
       " 'hybrid',\n",
       " 'national-geographic',\n",
       " 'oceans',\n",
       " 'osm',\n",
       " 'satellite',\n",
       " 'streets',\n",
       " 'streets-navigation-vector',\n",
       " 'streets-night-vector',\n",
       " 'streets-relief-vector',\n",
       " 'streets-vector',\n",
       " 'terrain',\n",
       " 'topo',\n",
       " 'topo-vector']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display available basemap styles\n",
    "map_for_FG.basemaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select \"dark-gray-vector\" as our basemap style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change basemap style\n",
    "map_for_FG.basemap='dark-gray-vector' \n",
    "map_for_CT.basemap='dark-gray-vector'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets add feature layer to the basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the feature layer onto the basemap, note that we are using feature layer collection as the parameter \n",
    "map_for_FG.add_layer(search_result[0], \n",
    "                     {\"renderer\":\"ClassedColorRenderer\",\"field_name\":\"Gi_Bin\", \"opacity\":0.7})\n",
    "# Add the legend\n",
    "map_for_FG.legend = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the feature layer onto the basemap, note that we are using feature layer collection as the parameter \n",
    "map_for_CT.add_layer(hotspot_hp_calls_CT, \n",
    "                     {\"renderer\":\"ClassedColorRenderer\",\"field_name\":\"Gi_Bin\", \"opacity\":0.7})\n",
    "# Add the legend\n",
    "map_for_CT.legend = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see feature layers are added onto the baseamaps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we walked through the common spatial workflow to finish our analysis using Python script with ArcGIS. You can see the strength of programming language in helping read large file, manage data, and analyze it.\n",
    "\n",
    "For more question about this exercise, please email to lin00297@umn.edu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
